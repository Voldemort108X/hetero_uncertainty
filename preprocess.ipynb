{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACDC Preprocess Not Normalized!\n",
    "1. Random split original training set to 80 training and 20 validation; and keep the 50 for testing\n",
    "2. Extract ED and ES pair and their corresponding segmentation from the sequence \n",
    "3. Crop the image into 128 x 128 for each slice\n",
    "4. No normalization is used at this point!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def centre_crop(img, size, centre):\n",
    "    img_new = np.zeros((size,size))\n",
    "    h1 = np.amin([size//2, centre[0]])\n",
    "    h2 = np.amin([size//2, img.shape[0]-centre[0]])\n",
    "    w1 = np.amin([size//2, centre[1]])\n",
    "    w2 = np.amin([size//2, img.shape[1]-centre[1]])\n",
    "    # print(centre[1]-w1)\n",
    "    # print(centre[1]+w2)\n",
    "    img_new[size//2-h1:size//2+h2,size//2-w1:size//2+w2] = img[centre[0]-h1:centre[0]+h2,centre[1]-w1:centre[1]+w2]\n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# Place your training and testing data in the following directories\n",
    "training_dir = '../../Dataset/ACDC/database/training/' \n",
    "\n",
    "patient_list = os.listdir(training_dir)\n",
    "random.shuffle(patient_list)\n",
    "\n",
    "train_list = patient_list[:80]\n",
    "val_list = patient_list[80:]\n",
    "\n",
    "testing_dir = '../../Dataset/ACDC/database/testing/'\n",
    "test_list = os.listdir(testing_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_ACDC(data_path, dest_path, name_list):\n",
    "    numOfSamples = len(name_list)\n",
    "\n",
    "    for i in range(numOfSamples):\n",
    "        file_dir = os.path.join(data_path, name_list[i])\n",
    "\n",
    "        with open(os.path.join(file_dir, 'Info.cfg')) as f:\n",
    "            line1 = f.readline()\n",
    "            line2 = f.readline()\n",
    "\n",
    "        ED_idx = '{:02d}'.format(int(line1.split(':')[1]))\n",
    "        ES_idx = '{:02d}'.format(int(line2.split(':')[1])) # type str\n",
    "\n",
    "        im_ED = nib.load(os.path.join(file_dir, name_list[i]+'_frame'+ED_idx+'.nii.gz')).get_fdata()\n",
    "        im_ES = nib.load(os.path.join(file_dir, name_list[i]+'_frame'+ES_idx+'.nii.gz')).get_fdata()\n",
    "\n",
    "        seg_ED = nib.load(os.path.join(file_dir, name_list[i]+'_frame'+ED_idx+'_gt.nii.gz')).get_fdata()\n",
    "        seg_ES = nib.load(os.path.join(file_dir, name_list[i]+'_frame'+ES_idx+'_gt.nii.gz')).get_fdata()\n",
    "\n",
    "        myo_ED = (seg_ED == 2)\n",
    "        myo_ES = (seg_ES == 2)\n",
    "\n",
    "        # extract the center slice myocardium centroid to the original\n",
    "        numOfSlices = im_ED.shape[-1]\n",
    "        center_ED = np.round(ndimage.measurements.center_of_mass(myo_ED[:,:,numOfSlices//2])).astype(np.uint8)\n",
    "\n",
    "        for z_idx in range(numOfSlices):\n",
    "            im_ED_slice = centre_crop(im_ED[:,:,z_idx], size=128, centre=center_ED)\n",
    "            im_ES_slice = centre_crop(im_ES[:,:,z_idx], size=128, centre=center_ED)\n",
    "\n",
    "            myo_ED_slice = centre_crop(myo_ED[:,:,z_idx], size=128, centre=center_ED)\n",
    "            myo_ES_slice = centre_crop(myo_ES[:,:,z_idx], size=128, centre=center_ED)\n",
    "\n",
    "            file = {'im_ED': im_ED_slice, 'im_ES': im_ES_slice, 'myo_ED': myo_ED_slice, 'myo_ES': myo_ES_slice}\n",
    "\n",
    "            file_name = name_list[i] + '_slice_' + str(z_idx) + '.mat'\n",
    "\n",
    "            savemat(os.path.join(dest_path, file_name), file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dest_dir = '../../Dataset/ACDC/train'\n",
    "if not os.path.exists(train_dest_dir):\n",
    "    os.makedirs(train_dest_dir)\n",
    "preprocess_ACDC(training_dir, train_dest_dir, train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dest_dir = '../../Dataset/ACDC/val'\n",
    "if not os.path.exists(val_dest_dir):\n",
    "    os.makedirs(val_dest_dir)\n",
    "preprocess_ACDC(training_dir, val_dest_dir, val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dest_dir = '../../Dataset/ACDC/test'\n",
    "if not os.path.exists(test_dest_dir):\n",
    "    os.makedirs(test_dest_dir)\n",
    "preprocess_ACDC(testing_dir, test_dest_dir, test_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMUS Preprocess Not Normalized!\n",
    "1. Random split the original 500 images to 60% training, 20 validation, 20 testing\n",
    "2. Extract ED/ES and segmentation for 2CH and 4CH\n",
    "3. Resize the image to 128 x 128\n",
    "4. No normalization is used at this point!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "# Place your downloaded in the following directory\n",
    "data_dir = '../../Dataset/CAMUS/database_nifti/'\n",
    "\n",
    "patient_list = os.listdir(data_dir)\n",
    "random.shuffle(patient_list)\n",
    "\n",
    "train_list = patient_list[:300]\n",
    "val_list = patient_list[300:400]\n",
    "test_list = patient_list[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "\n",
    "def preprocess_CAMUS(data_path, dest_path, name_list):\n",
    "    numOfSamples = len(name_list)\n",
    "\n",
    "    for i in range(numOfSamples):\n",
    "        folder_dir = os.path.join(data_path, name_list[i])\n",
    "\n",
    "        im_ED_2CH = nib.load(os.path.join(folder_dir, name_list[i]+'_2CH_ED.nii.gz')).get_fdata()\n",
    "        im_ES_2CH = nib.load(os.path.join(folder_dir, name_list[i]+'_2CH_ES.nii.gz')).get_fdata()\n",
    "\n",
    "        im_ED_4CH = nib.load(os.path.join(folder_dir, name_list[i]+'_4CH_ED.nii.gz')).get_fdata()\n",
    "        im_ES_4CH = nib.load(os.path.join(folder_dir, name_list[i]+'_4CH_ES.nii.gz')).get_fdata()\n",
    "\n",
    "        seg_ED_2CH = nib.load(os.path.join(folder_dir, name_list[i]+'_2CH_ED_gt.nii.gz')).get_fdata()\n",
    "        seg_ES_2CH = nib.load(os.path.join(folder_dir, name_list[i]+'_2CH_ES_gt.nii.gz')).get_fdata()     \n",
    "\n",
    "        seg_ED_4CH = nib.load(os.path.join(folder_dir, name_list[i]+'_4CH_ED_gt.nii.gz')).get_fdata()\n",
    "        seg_ES_4CH = nib.load(os.path.join(folder_dir, name_list[i]+'_4CH_ES_gt.nii.gz')).get_fdata()\n",
    "\n",
    "        out_shape = (128, 128)\n",
    "\n",
    "        im_ED_2CH_resize = resize(im_ED_2CH, out_shape)\n",
    "        im_ES_2CH_resize = resize(im_ES_2CH, out_shape)\n",
    "\n",
    "        im_ED_4CH_resize = resize(im_ED_4CH, out_shape)\n",
    "        im_ES_4CH_resize = resize(im_ES_4CH, out_shape)\n",
    "\n",
    "\n",
    "        myo_ED_2CH = (seg_ED_2CH == 2)\n",
    "        myo_ES_2CH = (seg_ES_2CH== 2)\n",
    "\n",
    "        myo_ED_4CH = (seg_ED_4CH == 2)\n",
    "        myo_ES_4CH = (seg_ES_4CH == 2)\n",
    "\n",
    "        myo_ED_2CH_resize = np.round(resize(myo_ED_2CH, out_shape))\n",
    "        myo_ES_2CH_resize = np.round(resize(myo_ES_2CH, out_shape))\n",
    "\n",
    "        myo_ED_4CH_resize = np.round(resize(myo_ED_4CH, out_shape))\n",
    "        myo_ES_4CH_resize = np.round(resize(myo_ES_4CH, out_shape))\n",
    "\n",
    "        file_2CH = {'im_ED': im_ED_2CH_resize, 'im_ES': im_ES_2CH_resize, 'myo_ED': myo_ED_2CH_resize, 'myo_ES':myo_ES_2CH_resize}\n",
    "        file_name_2CH = name_list[i] + '_2CH.mat'\n",
    "\n",
    "        file_4CH = {'im_ED': im_ED_4CH_resize, 'im_ES': im_ES_4CH_resize, 'myo_ED': myo_ED_4CH_resize, 'myo_ES':myo_ES_4CH_resize}\n",
    "        file_name_4CH = name_list[i] + '_4CH.mat'\n",
    "\n",
    "\n",
    "        savemat(os.path.join(dest_path, file_name_2CH), file_2CH)\n",
    "\n",
    "        savemat(os.path.join(dest_path, file_name_4CH), file_4CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dest_dir = '../../../Dataset/CAMUS/train'\n",
    "if not os.path.exists(train_dest_dir):\n",
    "    os.makedirs(train_dest_dir)\n",
    "preprocess_CAMUS(data_dir, train_dest_dir, train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dest_dir = '../../../Dataset/CAMUS/val'\n",
    "if not os.path.exists(val_dest_dir):\n",
    "    os.makedirs(val_dest_dir)\n",
    "preprocess_CAMUS(data_dir, val_dest_dir, val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dest_dir = '../../../Dataset/CAMUS/test'\n",
    "if not os.path.exists(test_dest_dir):\n",
    "    os.makedirs(test_dest_dir)\n",
    "preprocess_CAMUS(data_dir, test_dest_dir, test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hetero_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
